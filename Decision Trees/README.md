# Decision Trees
Implementing a decision tree from scratch and applying it to the task of classifying whether a mushroom is edible or poisonous! I wrote a compute_entropy() function that computes the entropy (measure of impurity) at a node, a helper function called split_dataset() that takes in the data at a node and a feature to split on and splits it into left and right branches, a function called information_gain() that takes in the training data, the indices at a node and a feature to split on and returns the information gain from the split, and a get_best_split() function to get the best feature to split on by computing the information gain from each feature and returning the feature that gives the maximum information gain.
